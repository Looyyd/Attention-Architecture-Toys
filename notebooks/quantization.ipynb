{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-24T15:33:34.701492Z",
     "start_time": "2023-06-24T15:32:42.029232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   1/1875 [..............................] - ETA: 5:39 - loss: 2.2823 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 17:32:44.592826: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2083 - accuracy: 0.9410 - val_loss: 0.0861 - val_accuracy: 0.9753\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0755 - accuracy: 0.9777 - val_loss: 0.0618 - val_accuracy: 0.9817\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0570 - accuracy: 0.9832 - val_loss: 0.0580 - val_accuracy: 0.9811\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0470 - accuracy: 0.9857 - val_loss: 0.0572 - val_accuracy: 0.9823\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 0.0569 - val_accuracy: 0.9821\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9821\n",
      "Accuracy before quantization: 0.9821000099182129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmp362zaaf7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmp362zaaf7/assets\n",
      "2023-06-24 17:33:34.087352: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-06-24 17:33:34.087365: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-06-24 17:33:34.087724: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmp362zaaf7\n",
      "2023-06-24 17:33:34.088426: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-06-24 17:33:34.088431: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmp362zaaf7\n",
      "2023-06-24 17:33:34.090446: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n",
      "2023-06-24 17:33:34.090860: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-06-24 17:33:34.109129: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmp362zaaf7\n",
      "2023-06-24 17:33:34.113788: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 26076 microseconds.\n",
      "2023-06-24 17:33:34.124862: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "INFO: Initialized TensorFlow Lite runtime.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_reshape_input:0 ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 44\u001B[0m\n\u001B[1;32m     42\u001B[0m input_details \u001B[38;5;241m=\u001B[39m interpreter\u001B[38;5;241m.\u001B[39mget_input_details()\n\u001B[1;32m     43\u001B[0m output_details \u001B[38;5;241m=\u001B[39m interpreter\u001B[38;5;241m.\u001B[39mget_output_details()\n\u001B[0;32m---> 44\u001B[0m \u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_details\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mindex\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m interpreter\u001B[38;5;241m.\u001B[39minvoke()\n\u001B[1;32m     46\u001B[0m predictions \u001B[38;5;241m=\u001B[39m interpreter\u001B[38;5;241m.\u001B[39mget_tensor(output_details[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:697\u001B[0m, in \u001B[0;36mInterpreter.set_tensor\u001B[0;34m(self, tensor_index, value)\u001B[0m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_tensor\u001B[39m(\u001B[38;5;28mself\u001B[39m, tensor_index, value):\n\u001B[1;32m    682\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001B[39;00m\n\u001B[1;32m    683\u001B[0m \n\u001B[1;32m    684\u001B[0m \u001B[38;5;124;03m  Note this copies data in `value`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    695\u001B[0m \u001B[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001B[39;00m\n\u001B[1;32m    696\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 697\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSetTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: Cannot set tensor: Got value of type FLOAT64 but expected type FLOAT32 for input 0, name: serving_default_reshape_input:0 "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T15:38:15.592798Z",
     "start_time": "2023-06-24T15:38:15.590728Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9821\n",
      "Accuracy before quantization: 0.9821000099182129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpz5_50vr4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpz5_50vr4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected input shape: [ 1 28 28]\n",
      "Predicted label: 7\n",
      "True label: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-24 17:42:33.198116: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-06-24 17:42:33.198131: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-06-24 17:42:33.198205: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpz5_50vr4\n",
      "2023-06-24 17:42:33.198932: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-06-24 17:42:33.198978: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpz5_50vr4\n",
      "2023-06-24 17:42:33.200814: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-06-24 17:42:33.217545: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpz5_50vr4\n",
      "2023-06-24 17:42:33.221364: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 23159 microseconds.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model accuracy before quantization\n",
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Accuracy before quantization:\", accuracy)\n",
    "\n",
    "# Convert the model to a quantized version\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the quantized model to a file\n",
    "with open('quantized_model.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "# Convert x_test to FLOAT32\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Select a single image from x_test for evaluation\n",
    "image_index = 0  # Choose the index of the image to evaluate\n",
    "image = x_test[image_index]\n",
    "image = image.reshape(28, 28, 1)  # Reshape to match the input shape of the quantized model\n",
    "\n",
    "# Load the quantized model\n",
    "interpreter = tf.lite.Interpreter(model_path='quantized_model.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details of the quantized model\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Check the expected input shape of the quantized model\n",
    "input_shape = input_details[0]['shape']\n",
    "print(\"Expected input shape:\", input_shape)\n",
    "\n",
    "# Resize the input image to match the expected input shape\n",
    "image_resized = tf.image.resize(image, (input_shape[1], input_shape[2]))\n",
    "image_input = image_resized.numpy().reshape(input_shape)\n",
    "\n",
    "# Set the input tensor to the quantized model\n",
    "interpreter.set_tensor(input_details[0]['index'], image_input)\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor of the quantized model\n",
    "output_tensor = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Perform prediction on the quantized model\n",
    "predicted_label = np.argmax(output_tensor)\n",
    "true_label = y_test[image_index]\n",
    "print(\"Predicted label:\", predicted_label)\n",
    "print(\"True label:\", true_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T15:42:33.270398Z",
     "start_time": "2023-06-24T15:42:32.212672Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after quantization: 0.982\n"
     ]
    }
   ],
   "source": [
    "# evaluate quantized model\n",
    "# Convert y_test to int64\n",
    "y_test = y_test.astype('int64')\n",
    "\n",
    "# Initialize a variable to store the number of correct predictions\n",
    "correct_predictions = 0\n",
    "\n",
    "# Iterate over the entire test set\n",
    "for i in range(len(x_test)):\n",
    "    # Prepare the input image\n",
    "    image = x_test[i].reshape(28, 28, 1)  # Reshape to match the input shape of the quantized model\n",
    "    image = tf.image.resize(image, (input_shape[1], input_shape[2]))  # Resize the image\n",
    "    image_input = image.numpy().reshape(input_shape)  # Reshape the image to match the input shape\n",
    "\n",
    "    # Set the input tensor\n",
    "    interpreter.set_tensor(input_details[0]['index'], image_input)\n",
    "\n",
    "    # Invoke the interpreter\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # Get the output tensor\n",
    "    output_tensor = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    # Perform prediction\n",
    "    predicted_label = np.argmax(output_tensor)\n",
    "    true_label = y_test[i]\n",
    "\n",
    "    # Compare the predicted label to the true label\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / len(x_test)\n",
    "\n",
    "print(\"Accuracy after quantization:\", accuracy)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T15:47:50.471954Z",
     "start_time": "2023-06-24T15:47:48.832299Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "## prequantization accuracy:\n",
    "313/313 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9821\n",
    "\n",
    "## postquantization accuracy:\n",
    "Accuracy after quantization: 0.982\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpbn8sgdmw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpbn8sgdmw/assets\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:765: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2023-06-24 17:50:52.779272: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-06-24 17:50:52.779286: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-06-24 17:50:52.779362: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpbn8sgdmw\n",
      "2023-06-24 17:50:52.780134: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-06-24 17:50:52.780145: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpbn8sgdmw\n",
      "2023-06-24 17:50:52.782276: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-06-24 17:50:52.800406: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/f3/jxhschwd67n3mthj9bst1d_w0000gn/T/tmpbn8sgdmw\n",
      "2023-06-24 17:50:52.805156: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 25794 microseconds.\n",
      "INFO: Initialized TensorFlow Lite runtime.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tensorflow/lite/kernels/reshape.cc:85 num_input_elements != num_output_elements (784 != 21952)Node number 3 (RESHAPE) failed to invoke.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m converter\u001B[38;5;241m.\u001B[39minference_input_type \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mint8  \u001B[38;5;66;03m# or tf.uint8 for TensorFlow Lite < 2.4.0\u001B[39;00m\n\u001B[1;32m     10\u001B[0m converter\u001B[38;5;241m.\u001B[39minference_output_type \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mint8  \u001B[38;5;66;03m# or tf.uint8 for TensorFlow Lite < 2.4.0\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m quantized_tflite_model \u001B[38;5;241m=\u001B[39m \u001B[43mconverter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:933\u001B[0m, in \u001B[0;36m_export_metrics.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(convert_func)\n\u001B[1;32m    931\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    932\u001B[0m   \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_and_export_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:911\u001B[0m, in \u001B[0;36mTFLiteConverterBase._convert_and_export_metrics\u001B[0;34m(self, convert_func, *args, **kwargs)\u001B[0m\n\u001B[1;32m    909\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_conversion_params_metric()\n\u001B[1;32m    910\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mprocess_time()\n\u001B[0;32m--> 911\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    912\u001B[0m elapsed_time_ms \u001B[38;5;241m=\u001B[39m (time\u001B[38;5;241m.\u001B[39mprocess_time() \u001B[38;5;241m-\u001B[39m start_time) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m\n\u001B[1;32m    913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1342\u001B[0m, in \u001B[0;36mTFLiteKerasModelConverterV2.convert\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;129m@_export_metrics\u001B[39m\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Converts a keras model based on instance variables.\u001B[39;00m\n\u001B[1;32m   1332\u001B[0m \n\u001B[1;32m   1333\u001B[0m \u001B[38;5;124;03m  Returns:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1340\u001B[0m \u001B[38;5;124;03m      Invalid quantization parameters.\u001B[39;00m\n\u001B[1;32m   1341\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1342\u001B[0m   saved_model_convert_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_as_saved_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1343\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m saved_model_convert_result:\n\u001B[1;32m   1344\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m saved_model_convert_result\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1325\u001B[0m, in \u001B[0;36mTFLiteKerasModelConverterV2._convert_as_saved_model\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1321\u001B[0m   graph_def, input_tensors, output_tensors \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1322\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_keras_to_saved_model(temp_dir))\n\u001B[1;32m   1323\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msaved_model_dir:\n\u001B[1;32m   1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mTFLiteKerasModelConverterV2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m-> 1325\u001B[0m \u001B[43m                 \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph_def\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_tensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_tensors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1326\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1327\u001B[0m   shutil\u001B[38;5;241m.\u001B[39mrmtree(temp_dir, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1141\u001B[0m, in \u001B[0;36mTFLiteConverterBaseV2.convert\u001B[0;34m(self, graph_def, input_tensors, output_tensors)\u001B[0m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;66;03m# Converts model.\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m result \u001B[38;5;241m=\u001B[39m _convert_graphdef(\n\u001B[1;32m   1136\u001B[0m     input_data\u001B[38;5;241m=\u001B[39mgraph_def,\n\u001B[1;32m   1137\u001B[0m     input_tensors\u001B[38;5;241m=\u001B[39minput_tensors,\n\u001B[1;32m   1138\u001B[0m     output_tensors\u001B[38;5;241m=\u001B[39moutput_tensors,\n\u001B[1;32m   1139\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconverter_kwargs)\n\u001B[0;32m-> 1141\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimize_tflite_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1142\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_quant_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquant_io\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexperimental_new_quantizer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:215\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m    214\u001B[0m   report_error_message(\u001B[38;5;28mstr\u001B[39m(error))\n\u001B[0;32m--> 215\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m error \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m ConverterError \u001B[38;5;28;01mas\u001B[39;00m converter_error:\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter_error\u001B[38;5;241m.\u001B[39merrors:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:871\u001B[0m, in \u001B[0;36mTFLiteConverterBase._optimize_tflite_model\u001B[0;34m(self, model, quant_mode, quant_io)\u001B[0m\n\u001B[1;32m    869\u001B[0m   q_bias_type \u001B[38;5;241m=\u001B[39m quant_mode\u001B[38;5;241m.\u001B[39mbias_type()\n\u001B[1;32m    870\u001B[0m   q_allow_float \u001B[38;5;241m=\u001B[39m quant_mode\u001B[38;5;241m.\u001B[39mis_allow_float()\n\u001B[0;32m--> 871\u001B[0m   model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_quantize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_in_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_out_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_activations_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    872\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mq_bias_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_allow_float\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    874\u001B[0m m_in_type \u001B[38;5;241m=\u001B[39m in_type \u001B[38;5;28;01mif\u001B[39;00m in_type \u001B[38;5;28;01melse\u001B[39;00m _dtypes\u001B[38;5;241m.\u001B[39mfloat32\n\u001B[1;32m    875\u001B[0m m_out_type \u001B[38;5;241m=\u001B[39m out_type \u001B[38;5;28;01mif\u001B[39;00m out_type \u001B[38;5;28;01melse\u001B[39;00m _dtypes\u001B[38;5;241m.\u001B[39mfloat32\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:613\u001B[0m, in \u001B[0;36mTFLiteConverterBase._quantize\u001B[0;34m(self, result, input_type, output_type, activations_type, bias_type, allow_float)\u001B[0m\n\u001B[1;32m    609\u001B[0m calibrate_quantize \u001B[38;5;241m=\u001B[39m _calibrator\u001B[38;5;241m.\u001B[39mCalibrator(result,\n\u001B[1;32m    610\u001B[0m                                             custom_op_registerers_by_name,\n\u001B[1;32m    611\u001B[0m                                             custom_op_registerers_by_func)\n\u001B[1;32m    612\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experimental_calibrate_only \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_new_quantizer:\n\u001B[0;32m--> 613\u001B[0m   calibrated \u001B[38;5;241m=\u001B[39m \u001B[43mcalibrate_quantize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcalibrate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    614\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepresentative_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_gen\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_experimental_calibrate_only:\n\u001B[1;32m    617\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m calibrated\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:215\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m    214\u001B[0m   report_error_message(\u001B[38;5;28mstr\u001B[39m(error))\n\u001B[0;32m--> 215\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m error \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001B[0m, in \u001B[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    204\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m ConverterError \u001B[38;5;28;01mas\u001B[39;00m converter_error:\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m converter_error\u001B[38;5;241m.\u001B[39merrors:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/optimize/calibrator.py:226\u001B[0m, in \u001B[0;36mCalibrator.calibrate\u001B[0;34m(self, dataset_gen)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;129m@convert_phase\u001B[39m(Component\u001B[38;5;241m.\u001B[39mOPTIMIZE_TFLITE_MODEL, SubComponent\u001B[38;5;241m.\u001B[39mCALIBRATE)\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalibrate\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_gen):\n\u001B[1;32m    218\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calibrates the model with specified generator.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \n\u001B[1;32m    220\u001B[0m \u001B[38;5;124;03m  Returns:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;124;03m    dataset_gen: A generator that generates calibration samples.\u001B[39;00m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 226\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_feed_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_gen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresize_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calibrator\u001B[38;5;241m.\u001B[39mCalibrate()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/LanguageDetection/lib/python3.10/site-packages/tensorflow/lite/python/optimize/calibrator.py:138\u001B[0m, in \u001B[0;36mCalibrator._feed_tensors\u001B[0;34m(self, dataset_gen, resize_input)\u001B[0m\n\u001B[1;32m    136\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calibrator\u001B[38;5;241m.\u001B[39mFeedTensor(input_array, signature_key)\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 138\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_calibrator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFeedTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_array\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: tensorflow/lite/kernels/reshape.cc:85 num_input_elements != num_output_elements (784 != 21952)Node number 3 (RESHAPE) failed to invoke."
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in x_test:\n",
    "        yield [np.array(input_value, dtype=np.float32, ndmin=2)]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8 for TensorFlow Lite < 2.4.0\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8 for TensorFlow Lite < 2.4.0\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T15:50:53.516047Z",
     "start_time": "2023-06-24T15:50:52.428946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
