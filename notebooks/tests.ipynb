{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:28.459790Z",
     "start_time": "2023-06-18T14:33:28.111317Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_parquet('../data/train-00000-of-00001-3d14582ea46e1b17.parquet')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:30.390032Z",
     "start_time": "2023-06-18T14:33:28.460352Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  English words/sentences French words/sentences\n0                     Hi.                 Salut!\n1                    Run!                Cours !\n2                    Run!               Courez !\n3                    Who?                  Qui ?\n4                    Wow!             Ça alors !",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 5 rows of dataset\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:30.397232Z",
     "start_time": "2023-06-18T14:33:30.390960Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  English words/sentences French words/sentences\n0                     Hi.                 Salut!\n1                    Run!                Cours !\n2                    Run!               Courez !\n3                    Who?                  Qui ?\n4                    Wow!             Ca alors !",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ca alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform dataset to ascii\n",
    "from unidecode import unidecode\n",
    "\n",
    "df_ascii = df.applymap(unidecode)\n",
    "\n",
    "\n",
    "df_ascii.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:31.063021Z",
     "start_time": "2023-06-18T14:33:30.395484Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# save the ascii dataset\n",
    "df_ascii.to_parquet('../data/train-00000-of-00001-3d14582ea46e1b17-ascii.parquet')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:31.132207Z",
     "start_time": "2023-06-18T14:33:31.075575Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "# max length of a cell:\n",
    "print(df_ascii.applymap(len).max().max())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:31.179657Z",
     "start_time": "2023-06-18T14:33:31.131976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                  language  text\n0  English words/sentences   Hi.\n1  English words/sentences  Run!\n2  English words/sentences  Run!\n3  English words/sentences  Who?\n4  English words/sentences  Wow!",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>English words/sentences</td>\n      <td>Hi.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>English words/sentences</td>\n      <td>Run!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>English words/sentences</td>\n      <td>Run!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>English words/sentences</td>\n      <td>Who?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>English words/sentences</td>\n      <td>Wow!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melted dataset\n",
    "df_melted = df_ascii.melt(var_name='language', value_name='text')\n",
    "\n",
    "df_melted.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:31.191563Z",
     "start_time": "2023-06-18T14:33:31.180234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# save the melted dataset\n",
    "df_melted.to_parquet('../data/train-00000-of-00001-3d14582ea46e1b17-ascii-melted.parquet')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:31.281507Z",
     "start_time": "2023-06-18T14:33:31.192190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350932\n"
     ]
    }
   ],
   "source": [
    "# length of the melted dataset\n",
    "print(len(df_melted))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:31.284152Z",
     "start_time": "2023-06-18T14:33:31.281925Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"$%&'()+,-./0123456789:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzUNK\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text, character to integers\n",
    "chars = sorted(list(set(''.join(df_melted['text']))))\n",
    "# add unknown character\n",
    "chars.append('UNK')\n",
    "\n",
    "\n",
    "print(''.join(chars))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:31.379276Z",
     "start_time": "2023-06-18T14:33:31.376737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 55, 66, 75, 74, 0, 74, 69, 75, 74, 0, 66, 59, 0, 67, 69, 68, 58, 59, 12, 0]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def encode_text(text: str) -> list:\n",
    "    return [chars.index(c) if c in chars else chars.index('UNK') for c in text]\n",
    "\n",
    "def decode_text(encoded_text: list) -> str:\n",
    "    return ''.join([chars[c] for c in encoded_text])\n",
    "\n",
    "print(encode_text('Salut tout le monde. '))\n",
    "print(decode_text(encode_text('hello world')))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:31.382413Z",
     "start_time": "2023-06-18T14:33:31.380223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "layers = tf.keras.layers\n",
    "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        assert embed_dim % num_heads == 0  # check if embed_dim is divisible by num_heads\n",
    "\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True) # (batch_size, seq_len, seq_len)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) # scalar value of the last dimension of key\n",
    "        #scale the score to avoid the gradient vanishing problem\n",
    "        scaled_score = score / tf.math.sqrt(dim_key) # (batch_size, seq_len, seq_len) / scalar\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) # (batch_size, seq_len, seq_len)\n",
    "\n",
    "        output = tf.matmul(weights, value)\n",
    "        # (batch_size, seq_len, seq_len) * (batch_size, num_heads, seq_len, embed_dim/num_heads) = (batch_size, num_heads, seq_len, embed_dim/num_heads)\n",
    "\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.embed_dim // self.num_heads))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(query, batch_size)  # (batch_size, num_heads, seq_len, embed_dim/num_heads)\n",
    "        key = self.separate_heads(key, batch_size)  # (batch_size, num_heads, seq_len, embed_dim/num_heads)\n",
    "        value = self.separate_heads(value, batch_size)  # (batch_size, num_heads, seq_len, embed_dim/num_heads)\n",
    "\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len, num_heads, embed_dim/num_heads)\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(concat_attention)  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:33:33.112333Z",
     "start_time": "2023-06-18T14:33:31.385847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "block_size = 8 # 8 characters per block\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    block_size: int = block_size\n",
    "    vocab_size: int = len(chars)\n",
    "    n_head: int = 8\n",
    "    n_embd: int = 32\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = False # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "config = Config()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:45:44.630262Z",
     "start_time": "2023-06-18T14:45:44.626023Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 8, 32)             2656      \n",
      "                                                                 \n",
      " multi_head_self_attention_4  (None, None, 32)         4224      \n",
      "  (MultiHeadSelfAttention)                                       \n",
      "                                                                 \n",
      " global_average_pooling1d_3   (None, 32)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 128)               4224      \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,874\n",
      "Trainable params: 27,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# define the model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten, GlobalAveragePooling1D\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(chars)+1, output_dim=config.n_embd, input_length=block_size),\n",
    "    MultiHeadSelfAttention(config.n_embd, config.n_head),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(128, activation='relu', input_shape=(config.n_head,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.build(input_shape=(batch_size, block_size, config.n_embd))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:45:45.212790Z",
     "start_time": "2023-06-18T14:45:45.165329Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "cost = 'categorical_crossentropy'\n",
    "optimizer = 'adam'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=cost, optimizer=optimizer, metrics=metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:45:46.988446Z",
     "start_time": "2023-06-18T14:45:46.978876Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8774/8774 [==============================] - 12s 1ms/step - loss: 0.1496 - accuracy: 0.9381 - val_loss: 0.2461 - val_accuracy: 0.9043\n",
      "Epoch 2/3\n",
      "8774/8774 [==============================] - 11s 1ms/step - loss: 0.0996 - accuracy: 0.9614 - val_loss: 0.1447 - val_accuracy: 0.9498\n",
      "Epoch 3/3\n",
      "8774/8774 [==============================] - 11s 1ms/step - loss: 0.0793 - accuracy: 0.9702 - val_loss: 0.1668 - val_accuracy: 0.9373\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x280582410>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Convert to list first\n",
    "x = df_melted['text'].apply(encode_text).apply(lambda x: x[:block_size]).to_list()\n",
    "\n",
    "# Pad sequences\n",
    "x = pad_sequences(x, maxlen=block_size, padding='post', truncating='post')\n",
    "\n",
    "y = pd.get_dummies(df_melted['language']).values  # convert DataFrame into a NumPy array\n",
    "\n",
    "model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    batch_size=32,\n",
    "    epochs=3,\n",
    "    validation_split=0.2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:46:31.393782Z",
     "start_time": "2023-06-18T14:45:47.864899Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350932, 8)\n"
     ]
    }
   ],
   "source": [
    "# Epoch 3/3\n",
    "# 8774/8774 [==============================] - 11s 1ms/step - loss: 0.0793 - accuracy: 0.9702 - val_loss: 0.1668 - val_accuracy: 0.9373\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:40:27.446721Z",
     "start_time": "2023-06-18T14:40:27.438545Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74 79 70 63 57 55 66  0]]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "English\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test the model on my own text\n",
    "my_text = 'typical'\n",
    "my_text_encoded = encode_text(my_text)\n",
    "my_text_encoded = pad_sequences([my_text_encoded], maxlen=block_size, padding='post', truncating='post')\n",
    "\n",
    "print(my_text_encoded)\n",
    "\n",
    "if np.argmax(model.predict(my_text_encoded)) == 1:\n",
    "    print('French')\n",
    "else:\n",
    "    print('English')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:50:07.617079Z",
     "start_time": "2023-06-18T14:50:07.593153Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "                  language  text\n0  English words/sentences   Hi.\n1  English words/sentences  Run!\n2  English words/sentences  Run!\n3  English words/sentences  Who?\n4  English words/sentences  Wow!",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>English words/sentences</td>\n      <td>Hi.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>English words/sentences</td>\n      <td>Run!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>English words/sentences</td>\n      <td>Run!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>English words/sentences</td>\n      <td>Who?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>English words/sentences</td>\n      <td>Wow!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-18T14:51:49.709890Z",
     "start_time": "2023-06-18T14:51:49.704843Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
