{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:01:27.602835Z",
     "start_time": "2023-06-17T14:01:27.225598Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_parquet('../data/train-00000-of-00001-3d14582ea46e1b17.parquet')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:04:45.582315Z",
     "start_time": "2023-06-17T14:04:45.464177Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  English words/sentences French words/sentences\n0                     Hi.                 Salut!\n1                    Run!                Cours !\n2                    Run!               Courez !\n3                    Who?                  Qui ?\n4                    Wow!             Ça alors !",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 5 rows of dataset\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:04:47.083160Z",
     "start_time": "2023-06-17T14:04:47.063573Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  English words/sentences French words/sentences\n0                     Hi.                 Salut!\n1                    Run!                Cours !\n2                    Run!               Courez !\n3                    Who?                  Qui ?\n4                    Wow!             Ca alors !",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English words/sentences</th>\n      <th>French words/sentences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ca alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform dataset to ascii\n",
    "from unidecode import unidecode\n",
    "\n",
    "df_ascii = df.applymap(unidecode)\n",
    "\n",
    "\n",
    "df_ascii.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:10:09.828705Z",
     "start_time": "2023-06-17T14:10:09.197807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# save the ascii dataset\n",
    "df_ascii.to_parquet('../data/train-00000-of-00001-3d14582ea46e1b17-ascii.parquet')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:10:38.730825Z",
     "start_time": "2023-06-17T14:10:38.670503Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "# max length of a cell:\n",
    "print(df_ascii.applymap(len).max().max())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:17:24.679623Z",
     "start_time": "2023-06-17T14:17:24.634715Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                  language  text\n0  English words/sentences   Hi.\n1  English words/sentences  Run!\n2  English words/sentences  Run!\n3  English words/sentences  Who?\n4  English words/sentences  Wow!",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>English words/sentences</td>\n      <td>Hi.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>English words/sentences</td>\n      <td>Run!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>English words/sentences</td>\n      <td>Run!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>English words/sentences</td>\n      <td>Who?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>English words/sentences</td>\n      <td>Wow!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melted dataset\n",
    "df_melted = df_ascii.melt(var_name='language', value_name='text')\n",
    "\n",
    "df_melted.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:22:01.881556Z",
     "start_time": "2023-06-17T14:22:01.868500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# save the melted dataset\n",
    "df_melted.to_parquet('../data/train-00000-of-00001-3d14582ea46e1b17-ascii-melted.parquet')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:26:31.822293Z",
     "start_time": "2023-06-17T14:26:31.746651Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350932\n"
     ]
    }
   ],
   "source": [
    "# length of the melted dataset\n",
    "print(len(df_melted))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:28:28.500843Z",
     "start_time": "2023-06-17T14:28:28.497067Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"$%&'()+,-./0123456789:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzUNK\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text, character to integers\n",
    "chars = sorted(list(set(''.join(df_melted['text']))))\n",
    "# add unknown character\n",
    "chars.append('UNK')\n",
    "\n",
    "\n",
    "print(''.join(chars))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:52:33.655612Z",
     "start_time": "2023-06-17T14:52:33.653668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 55, 66, 75, 74, 0, 74, 69, 75, 74, 0, 66, 59, 0, 67, 69, 68, 58, 59, 12, 0]\n",
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def encode_text(text: str) -> list:\n",
    "    return [chars.index(c) if c in chars else chars.index('UNK') for c in text]\n",
    "\n",
    "def decode_text(encoded_text: list) -> str:\n",
    "    return ''.join([chars[c] for c in encoded_text])\n",
    "\n",
    "print(encode_text('Salut tout le monde. '))\n",
    "print(decode_text(encode_text('hello world')))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T14:54:47.157999Z",
     "start_time": "2023-06-17T14:54:47.152697Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,922\n",
      "Trainable params: 17,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_size = 8 # 8 characters per block\n",
    "\n",
    "\n",
    "# define the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(block_size,)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T15:14:41.727944Z",
     "start_time": "2023-06-17T15:14:41.705480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "cost = 'categorical_crossentropy'\n",
    "optimizer = 'adam'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(loss=cost, optimizer=optimizer, metrics=metrics)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T15:14:42.346798Z",
     "start_time": "2023-06-17T15:14:42.339521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8774/8774 [==============================] - 5s 545us/step - loss: 0.3448 - accuracy: 0.8506 - val_loss: 0.5005 - val_accuracy: 0.8150\n",
      "Epoch 2/10\n",
      "8774/8774 [==============================] - 5s 540us/step - loss: 0.2058 - accuracy: 0.9105 - val_loss: 0.3760 - val_accuracy: 0.8460\n",
      "Epoch 3/10\n",
      "8774/8774 [==============================] - 5s 568us/step - loss: 0.1622 - accuracy: 0.9334 - val_loss: 0.2944 - val_accuracy: 0.8848\n",
      "Epoch 4/10\n",
      "8774/8774 [==============================] - 5s 618us/step - loss: 0.1328 - accuracy: 0.9490 - val_loss: 0.2495 - val_accuracy: 0.9042\n",
      "Epoch 5/10\n",
      "8774/8774 [==============================] - 5s 603us/step - loss: 0.1199 - accuracy: 0.9543 - val_loss: 0.2434 - val_accuracy: 0.9045\n",
      "Epoch 6/10\n",
      "8774/8774 [==============================] - 5s 559us/step - loss: 0.1124 - accuracy: 0.9572 - val_loss: 0.2242 - val_accuracy: 0.9184\n",
      "Epoch 7/10\n",
      "8774/8774 [==============================] - 5s 569us/step - loss: 0.1070 - accuracy: 0.9598 - val_loss: 0.2233 - val_accuracy: 0.9087\n",
      "Epoch 8/10\n",
      "8774/8774 [==============================] - 5s 609us/step - loss: 0.1027 - accuracy: 0.9612 - val_loss: 0.2406 - val_accuracy: 0.9061\n",
      "Epoch 9/10\n",
      "8774/8774 [==============================] - 5s 596us/step - loss: 0.0989 - accuracy: 0.9623 - val_loss: 0.1673 - val_accuracy: 0.9311\n",
      "Epoch 10/10\n",
      "8774/8774 [==============================] - 5s 592us/step - loss: 0.0963 - accuracy: 0.9636 - val_loss: 0.1956 - val_accuracy: 0.9325\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x16c21fc70>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Convert to list first\n",
    "x = df_melted['text'].apply(encode_text).apply(lambda x: x[:block_size]).to_list()\n",
    "\n",
    "# Pad sequences\n",
    "x = pad_sequences(x, maxlen=block_size, padding='post', truncating='post')\n",
    "\n",
    "y = pd.get_dummies(df_melted['language']).values  # convert DataFrame into a NumPy array\n",
    "\n",
    "model.fit(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_split=0.2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T15:15:43.957582Z",
     "start_time": "2023-06-17T15:14:43.203561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[79 69 75 70 63  0  0  0]]\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "English\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test the model on my own text\n",
    "my_text = 'youpi'\n",
    "my_text_encoded = encode_text(my_text)\n",
    "my_text_encoded = pad_sequences([my_text_encoded], maxlen=block_size, padding='post', truncating='post')\n",
    "\n",
    "print(my_text_encoded)\n",
    "\n",
    "if np.argmax(model.predict(my_text_encoded)) == 0:\n",
    "    print('French')\n",
    "else:\n",
    "    print('English')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-17T15:17:40.550914Z",
     "start_time": "2023-06-17T15:17:40.525213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
